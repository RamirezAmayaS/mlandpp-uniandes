{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Risk Adjustment and Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading health data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Import pandas and assign to it the pd alias\n",
    "import pandas as pd\n",
    "\n",
    "# Load csv to pd.dataframe using pd.read_csv\n",
    "df_salud = pd.read_csv('../suficiencia.csv')\n",
    "\n",
    "# Index is not appropiately set\n",
    "print(df_salud.head())\n",
    "\n",
    "# pd.read_csv inferred unconvenient data types for some columns\n",
    "for columna in df_salud.columns:\n",
    "    print(columna,df_salud[columna].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# TO DO: declare a dict named dtype with column names as keys and data types as values\n",
    "# We need MUNI_2010, MUNI_2011, DPTO_2010 and DPTO_2011 as data type 'category'. We need SEXO_M and SEXO_F as bool as well.\n",
    "dtype = {}\n",
    "\n",
    "# TO DO: declare a integer variable with the column number to be taken as index \n",
    "index_col = \n",
    "\n",
    "# We reload csv file using index_col and dtype parameters  \n",
    "df_salud = pd.read_csv('../suficiencia.csv',index_col= index_col,dtype=dtype)\n",
    "\n",
    "# Index is appropriately set\n",
    "print(df_salud.head())\n",
    "\n",
    "# TO DO: check pd.read_csv has convenient data types \n",
    "# Check last code cell for help.\n",
    "\n",
    "# TO DO: print mean value for expenditure in 2010 and 2011\n",
    "# Expenditure is given by variables 'VALOR_TOT_2010' and 'VALOR_TOT_2011' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring health data\n",
    "We are interested in exploring risk profiles of individuals. Lets estimate expenditure and enrollee density distribution for different expenditure intervals. We will consider intervals of \\$10,000 COP between \\$0 and \\$3,000,000 COP. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will be using plotly to graph the distributions. \n",
    "import plotly \n",
    "import plotly.graph_objs as go \n",
    "plotly.offline.init_notebook_mode(connected=True)\n",
    "\n",
    "# Set interval and step size\n",
    "tamanho = 10**6*3\n",
    "step_size = 10**4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enrollee distribution is straightforward using plotly. \n",
    "trace2010 = go.Histogram(\n",
    "                x=df_salud['VALOR_TOT_2010'],\n",
    "                name='2010',\n",
    "                histnorm='probability',\n",
    "                xbins=dict(start=0.0,end=tamanho,size=step_size),\n",
    "                legendgroup='2010'\n",
    "            )\n",
    "\n",
    "# TO DO: declare a second trace for the 2011 enrollee distribution\n",
    "trace2011 = go.Histogram(\n",
    "                \n",
    "            )\n",
    "\n",
    "layout = go.Layout(\n",
    "            legend=dict(\n",
    "                xanchor='center',\n",
    "                yanchor='top',\n",
    "                orientation='h',\n",
    "                y=-0.25,\n",
    "                x=0.5,\n",
    "            ),\n",
    "            yaxis=dict(\n",
    "                title='Density',\n",
    "                rangemode='tozero'\n",
    "            ),\n",
    "            xaxis=dict(\n",
    "                title='Expenditure'\n",
    "            ),\n",
    "            title='Enrolle density'\n",
    "         )\n",
    "\n",
    "# TO DO Add both traces to a list and pass it to go.Figure data parameter\n",
    "fig = go.Figure(data=, layout=layout)\n",
    "plotly.offline.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expenditure distribution needs extra work since we are accumulating expenditure and not enrollees. For this purpose we first sort enrollees, then we calculate accumulated expenditure up to each interval and normalize it by total expenditure and finally we differentiate the series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: import numpy with alias np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: write function to calculate expenditure cumulative density for a given year\n",
    "def calculate_expenditure_cumulative_density(year):\n",
    "        \n",
    "    return cumulative_density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "density_2010 = np.diff(calculate_expenditure_cumulative_density('2010'))\n",
    "density_2011 = np.diff(calculate_expenditure_cumulative_density('2011'))\n",
    "\n",
    "# TO DO: declare a trace for 2010 expenditure distribution. Use color '#1f77b4' for markers.\n",
    "trace_2010 = go.Scatter(\n",
    "                \n",
    "             )\n",
    "\n",
    "trace_2011 = go.Scatter(\n",
    "                x=list(range(0,tamanho,step_size)),\n",
    "                y=density_2011,\n",
    "                legendgroup='2011',\n",
    "                name='2011',\n",
    "                marker=dict(color='#ff7f0e'),\n",
    "                type='bar'\n",
    "             )\n",
    "\n",
    "layout = go.Layout(\n",
    "            legend=dict(\n",
    "                xanchor='center',\n",
    "                yanchor='top',\n",
    "                orientation='h',\n",
    "                y=-0.25,\n",
    "                x=0.5,\n",
    "            ),\n",
    "            yaxis=dict(\n",
    "                title='Density',\n",
    "                rangemode='tozero'\n",
    "            ),\n",
    "            xaxis=dict(\n",
    "                title='Expenditure'\n",
    "            ),\n",
    "            title='Expenditure density'\n",
    "         )\n",
    "\n",
    "# Add both traces to a list and pass it to go.Figure data parameter. Add the layout parameter as well.\n",
    "fig = go.Figure(data=,layout=)\n",
    "plotly.offline.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about cumulative density for enrollees and expenditure? Enrollee cumulative density needs some extra work since we did not explicitly calculate enrollee density before. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will be using scipy\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: scipy.stats.percentileofscore(series,score) returns percentile value of score in series\n",
    "def calculate_enrollee_cumulative_density(year):\n",
    "    \n",
    "    return cumulative_density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enrollee_cumulative_density_2010 = calculate_enrollee_cumulative_density('2010')\n",
    "enrollee_cumulative_density_2011 = calculate_enrollee_cumulative_density('2011')\n",
    "expenditure_cumulative_density_2010 = calculate_expenditure_cumulative_density('2010')\n",
    "expenditure_cumulative_density_2011 = calculate_expenditure_cumulative_density('2011')\n",
    "\n",
    "# TO DO: Create cumulative expenditure and enrollees traces and plot them. Use previous color conventions.\n",
    "trace_enrollee_2010 = go.Scatter(\n",
    "                        \n",
    "                     )\n",
    "\n",
    "trace_enrollee_2011 = go.Scatter(\n",
    "                            \n",
    "                      )\n",
    "\n",
    "trace_expenditure_2010 = go.Scatter(\n",
    "                            \n",
    "                         )\n",
    "\n",
    "\n",
    "trace_expenditure_2011 = go.Scatter(\n",
    "                            \n",
    "                         )\n",
    "\n",
    "layout = go.Layout(\n",
    "            legend=dict(\n",
    "                xanchor='center',\n",
    "                yanchor='top',\n",
    "                orientation='h',\n",
    "                y=-0.25,\n",
    "                x=0.5,\n",
    "            ),\n",
    "            yaxis=dict(\n",
    "                title='Cumulative density (%)',\n",
    "                rangemode='tozero'\n",
    "            ),\n",
    "            xaxis=dict(\n",
    "                title='Expenditure'\n",
    "            ),\n",
    "            title='Cumulative density of enrollees and expenditure'\n",
    "         )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmarking the problem\n",
    "Before fitting any models it is convenient to have a benchmark from a model as simple as possible. We estimate the mean absolute error (MAE) of the simple model \n",
    "\n",
    "$$ y_{it}^{pred} = \\frac{1}{N}\\sum_{N}{y_{it}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ymean = df_salud['VALOR_TOT_2011'].mean()\n",
    "\n",
    "# TO DO : write a function that calculates beanchmark MAE\n",
    "def calculate_benchmark_mae(row):\n",
    "    \n",
    "    return mae\n",
    "\n",
    "print('BENCHMARK MAE',df_salud.apply(calculate_mae,axis=1).mean())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSPS risk adjustment \n",
    "Colombian Ministry of Health and Social Protection currently employs a linear regression of annual health expenditure on sociodemographic risk factors that include gender, age groups and location as the risk-adjustment mechanism.\n",
    "\n",
    "<br/>\n",
    "$$\n",
    "y_{it} = \\beta_{0} + \\sum_{K}{\\beta_{j}D_{jit}} + \\epsilon_{i}\n",
    "$$\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start by calculating age groups from variable 'EDAD_2011'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Creating a grouping variable is straightforward with pd.cut\n",
    "bins = [0,1,4,18,44,49,54,59,64,69,74,150]\n",
    "labels = ['0_1','2_4','5_18','19_44','45_49','50_54','55_59','60_64','65_69','70_74','74_']\n",
    "df_salud['AGE_GROUP'] = pd.cut(df_salud['EDAD_2011'],bins,labels=labels,include_lowest=True)\n",
    "print(df_salud[['EDAD_2011','AGE_GROUP']])\n",
    "\n",
    "# We also need to create dummy variables using pd.get_dummies\n",
    "age_group_dummies = pd.get_dummies(df_salud['AGE_GROUP'],prefix='AGE_GROUP')\n",
    "df_salud = pd.concat([df_salud,age_group_dummies],axis=1)\n",
    "for column in df_salud.columns:\n",
    "    print(column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to group location codes into government defined categories. This requires some extra work. Make sure you have divipola.csv file in your home. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Download divipola.csv from your email and mo\n",
    "divipola = pd.read_csv('../divipola.csv',index_col=0)\n",
    "\n",
    "def give_location_group(row,divipola=divipola):\n",
    "    codigo_dpto = str(row['DPTO_2011']).rjust(2,'0')\n",
    "    codigo_muni = str(row['MUNI_2011']).rjust(3,'0')\n",
    "    codigo = codigo_dpto + codigo_muni\n",
    "    try:\n",
    "        grupo = divipola.loc[int(codigo)]['zona']\n",
    "    # Exception management for a single observation where last digit of municipality code is not valid\n",
    "    except KeyError:\n",
    "        return 'C'\n",
    "    return grupo\n",
    "\n",
    "location_group_dummies = pd.get_dummies(df_salud.apply(give_location_group,axis=1),prefix='LOCATION_GROUP')\n",
    "df_salud = pd.concat([df_salud,location_group_dummies],axis=1)\n",
    "for column in df_salud.columns:\n",
    "    print(column)                      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to fit MSPS linear model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will be using sklearn\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature space\n",
    "# One reference category is excluded for each dummy group\n",
    "features = ['SEXO_M',\n",
    "            'AGE_GROUP_2_4',\n",
    "            'AGE_GROUP_5_18',\n",
    "            'AGE_GROUP_19_44',\n",
    "            'AGE_GROUP_45_49',\n",
    "            'AGE_GROUP_50_54',\n",
    "            'AGE_GROUP_55_59',\n",
    "            'AGE_GROUP_60_64',\n",
    "            'AGE_GROUP_65_69',\n",
    "            'AGE_GROUP_70_74',\n",
    "            'AGE_GROUP_74_',\n",
    "            'LOCATION_GROUP_N',\n",
    "            'LOCATION_GROUP_Z',]\n",
    "\n",
    "# Target space\n",
    "target = ['VALOR_TOT_2011']\n",
    "\n",
    "# TO DO: calculate 10 cv mae for linear regression model using sklearn.model_selection.cross_val_score. Take a look at the needed parameters.\n",
    "reg = linear_model.LinearRegression()\n",
    "neg_mae = cross_val_score(estimator=,X=,y=,cv=,scoring=)\n",
    "print('REGRESSION MAE',-1*neg_mae.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = reg.fit(df_salud[features].values,df_salud[target].values)\n",
    "\n",
    "# TO DO: predict over enrollees with enrollees with 2011 expenditure above $3,000,000\n",
    "upper = \n",
    "y_pred_upper = [y[0] for y in reg.predict(upper[features])]\n",
    "print('REGRESSION MAE UPPER',(y_pred_upper-upper['VALOR_TOT_2011']).mean())\n",
    "\n",
    "# TO DO: predict over enrollees with enrollees with 2011 expenditure below or equal to $3,000,000\n",
    "lower = \n",
    "y_pred_lower = [y[0] for y in reg.predict(lower[features])]\n",
    "print('REGRESSION MAE LOWER',(y_pred_lower-lower['VALOR_TOT_2011']).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Risk adjustment using machine learning\n",
    "How about a regression tree?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will be using sklearn\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature space\n",
    "# One reference category is excluded for each dummy group\n",
    "features = ['SEXO_M',\n",
    "            'AGE_GROUP_2_4',\n",
    "            'AGE_GROUP_5_18',\n",
    "            'AGE_GROUP_19_44',\n",
    "            'AGE_GROUP_45_49',\n",
    "            'AGE_GROUP_50_54',\n",
    "            'AGE_GROUP_55_59',\n",
    "            'AGE_GROUP_60_64',\n",
    "            'AGE_GROUP_65_69',\n",
    "            'AGE_GROUP_70_74',\n",
    "            'AGE_GROUP_74_',\n",
    "            'LOCATION_GROUP_N',\n",
    "            'LOCATION_GROUP_Z',]\n",
    "\n",
    "# Target space\n",
    "target = ['VALOR_TOT_2011']\n",
    "\n",
    "reg_tree = DecisionTreeRegressor(min_samples_leaf=1000)\n",
    "neg_mae = cross_val_score(estimator=,X=,y=,cv=,scoring=)\n",
    "print('TREE REGRESSION MAE',-1*neg_mae.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does a tree look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use modules from sklearn, ipython and pydotplus to visualize trees\n",
    "from sklearn.externals.six import StringIO\n",
    "from IPython.display import Image, display\n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tree(tree):\n",
    "    dot_data = StringIO()\n",
    "    export_graphviz(\n",
    "        tree,\n",
    "        out_file=dot_data,\n",
    "        filled=True,\n",
    "        special_characters=True,\n",
    "        precision=0,\n",
    "        feature_names=features\n",
    "    )\n",
    "    graph = pydotplus.graph_from_dot_data(dot_data.getvalue())\n",
    "    display(Image(graph.create_png()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_tree = DecisionTreeRegressor(min_samples_leaf=1000)\n",
    "reg_tree = reg_tree.fit(df_salud[features].values,df_salud[target].values)\n",
    "plot_tree(reg_tree)\n",
    "\n",
    "upper = df_salud[df_salud['VALOR_TOT_2011'] > (3*10**6)]\n",
    "y_pred_upper = reg_tree.predict(upper[features])\n",
    "print('TREE REGRESSION MAE UPPER',(y_pred_upper-upper['VALOR_TOT_2011']).mean())\n",
    "\n",
    "lower = df_salud[df_salud['VALOR_TOT_2011'] <= (3*10**6)]\n",
    "y_pred_lower = reg_tree.predict(lower[features])\n",
    "print('TREE REGRESSION MAE LOWER',(y_pred_lower-lower['VALOR_TOT_2011']).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature space\n",
    "# One reference category is excluded for each dummy group\n",
    "features = ['SEXO_M',\n",
    "            'AGE_GROUP_2_4',\n",
    "            'AGE_GROUP_5_18',\n",
    "            'AGE_GROUP_19_44',\n",
    "            'AGE_GROUP_45_49',\n",
    "            'AGE_GROUP_50_54',\n",
    "            'AGE_GROUP_55_59',\n",
    "            'AGE_GROUP_60_64',\n",
    "            'AGE_GROUP_65_69',\n",
    "            'AGE_GROUP_70_74',\n",
    "            'AGE_GROUP_74_',\n",
    "            'LOCATION_GROUP_N',\n",
    "            'LOCATION_GROUP_Z',\n",
    "            'DIAG_1_C_2010',\n",
    "            'DIAG_1_P_2010',\n",
    "            'DIAG_1_D_2010',]\n",
    "\n",
    "# Target space\n",
    "target = ['VALOR_TOT_2011']\n",
    "\n",
    "reg_tree = DecisionTreeRegressor(min_samples_leaf=100)\n",
    "neg_mae = cross_val_score(estimator=reg_tree,X=df_salud[features],y=df_salud[target],cv=10,scoring='neg_mean_absolute_error')\n",
    "print('TREE REGRESSION MAE',-1*neg_mae.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_tree = DecisionTreeRegressor(min_samples_leaf=100)\n",
    "reg_tree = reg_tree.fit(df_salud[features].values,df_salud[target].values)\n",
    "plot_tree(reg_tree)\n",
    "\n",
    "upper = df_salud[df_salud['VALOR_TOT_2011'] > (3*10**6)]\n",
    "y_pred_upper = reg_tree.predict(upper[features])\n",
    "print('TREE REGRESSION MAE UPPER',(y_pred_upper-upper['VALOR_TOT_2011']).mean())\n",
    "\n",
    "lower = df_salud[df_salud['VALOR_TOT_2011'] <= (3*10**6)]\n",
    "y_pred_lower = reg_tree.predict(lower[features])\n",
    "print('TREE REGRESSION MAE LOWER',(y_pred_lower-lower['VALOR_TOT_2011']).mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlandpp",
   "language": "python",
   "name": "mlandpp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
